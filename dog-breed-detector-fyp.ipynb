{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Final Project: Dog breed detector**","metadata":{"id":"kvos-Q8MHcXW"}},{"cell_type":"markdown","source":"## **Import**","metadata":{"id":"QjghTGvLV6tV"}},{"cell_type":"code","source":"!pip install tensorflow==2.8.0\n!pip install tensorflow-addons","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftz8LU5ALJsG","outputId":"de276331-a18b-475d-952b-a108554f5184","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall tf-keras -y\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXLcmpAPLudc","outputId":"f0490751-3f04-46be-e41b-3d10d8cf5258","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow==2.8.0\n!pip install tensorflow-addons","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGgNLGlEMDJM","outputId":"af09e847-28ba-4af0-d28b-0a1369b922d1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport time\nimport json\nfrom IPython.core.display import HTML\nfrom matplotlib import pyplot as plt\nimport matplotlib.ticker as mticker\n%matplotlib inline\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n\n# Import pretrained models\nfrom tensorflow.keras.applications import ResNet50V2,VGG16, InceptionV3, MobileNetV2, DenseNet121\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport xml.etree.ElementTree as ET # for parsing XML\nfrom PIL import Image # to read images\nimport tensorflow_datasets as tfds\nimport tensorflow_addons as tfa","metadata":{"id":"oL-L6apNHXqT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ce2655e-3625-412b-f359-fe6692b43920","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# https://www.tensorflow.org/guide/data_performance\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"id":"bYkelguNwNKS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"tensorflow version\", tf.__version__)\nprint(\"keras version\", tf.keras.__version__)","metadata":{"id":"vyFbPAACzp2h","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6aa54db5-2480-4cd8-f897-9d0cf2c45dbe","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Test GPU + RAM**","metadata":{"id":"doaI0Fe_WRBs"}},{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\n\nif gpu_info.find('failed') >= 0:\n  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n  print('and then re-execute this cell.')\n\nelse:\n  print(gpu_info)\n\n\nfrom psutil import virtual_memory\nram_gb = virtual_memory().total / 1e9\nprint('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n\nif ram_gb < 20:\n  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n  print('re-execute this cell.')\n\nelse:\n  print('You are using a high-RAM runtime!')","metadata":{"id":"Rzmh4AoKWZtn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"568bd5f0-cfb1-4aa6-9c44-c3abab5d9951","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Dog DataSet**","metadata":{"id":"HRiVPEAeawaz"}},{"cell_type":"code","source":"!rm -rf DatasetStore","metadata":{"id":"XlSxslYp5dF8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport tarfile\ndataset_path = \"DatasetStore\"\n\n# Download and extract dataset\nif not os.path.exists(dataset_path):\n  os.mkdir(dataset_path)\n  packet_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n  packet_file = os.path.basename(packet_url)\n  packet_file = os.path.join(dataset_path, packet_file)\n  with requests.get(packet_url, stream=True) as r:\n      r.raise_for_status()\n      with open(packet_file, 'wb') as f:\n          for chunk in r.iter_content(chunk_size=8192):\n              f.write(chunk)\n\n\n\n  with tarfile.open(packet_file) as tfile:\n    tfile.extractall(dataset_path)\n\n  packet_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar\"\n  packet_file = os.path.basename(packet_url)\n  packet_file = os.path.join(dataset_path, packet_file)\n  with requests.get(packet_url, stream=True) as r:\n      r.raise_for_status()\n      with open(packet_file, 'wb') as f:\n          for chunk in r.iter_content(chunk_size=8192):\n              f.write(chunk)\n\n  with tarfile.open(packet_file) as tfile:\n    tfile.extractall(dataset_path)","metadata":{"id":"OztswEIO-ZS7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Display some training images**\n\n\n\n---\n\n\n","metadata":{"id":"vI8ruFr8DYow"}},{"cell_type":"code","source":"# https://www.kaggle.com/gtimoshaz/dataset-reading-demo\nbreed_list = os.listdir('DatasetStore/Annotation/') # list of all breeds for further demo\n# Train images\nfig = plt.figure(figsize=(15,8))\nfor i in range(15):\n    axs = fig.add_subplot(3,5,i+1)\n    breed = np.random.choice(breed_list) # random breed\n    dog = np.random.choice(os.listdir('DatasetStore/Annotation/' + breed)) # random image\n    img = Image.open('DatasetStore/Images/' + breed + '/' + dog + '.jpg')\n    tree = ET.parse('DatasetStore/Annotation/' + breed + '/' + dog) # init parser for file given\n    root = tree.getroot()\n    object_1 = root.findall('object')[0]; # finding all dogs. An array\n    name = object_1.find('name').text;\n    axs.set_title(name)\n    plt.imshow(img)\n    plt.axis('off')\n\nplt.suptitle(\"Sample Dog Images\")\nplt.show()","metadata":{"id":"nO7OevrxDa57","colab":{"base_uri":"https://localhost:8080/","height":732},"outputId":"f392fbfc-8d42-409c-9e83-51fa94d71721","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"breed_list = os.listdir('DatasetStore/Annotation/'); # list of all breeds for further demo\nbreed_list.sort()\n\nfor i,breed in enumerate(breed_list):\n  breed_list[i] = breed[10:];\n\n# Create label index for easy lookup\nlabel2index = dict((name, index) for index, name in enumerate(breed_list))\nindex2label = dict((index, name) for index, name in enumerate(breed_list))\nprint(breed_list[:3])","metadata":{"id":"3d1a1A_ETcwt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e8a069a-c888-41a4-b4f9-020f17d18a2d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Load data**","metadata":{"id":"bUlu2JS03J9r"}},{"cell_type":"code","source":"breed_list = os.listdir('DatasetStore/Annotation/') # list of all breeds for further demo\nbreed_list.sort()\n\n# Create label index for easy lookup\nlabel2index = dict((name, index) for index, name in enumerate(breed_list))\nindex2label = dict((index, name) for index, name in enumerate(breed_list))\n\nimages = []\nannotations =[]\n\nfor breed in breed_list:\n  image_files = os.listdir('DatasetStore/Images/' + breed)\n  image_files.sort()\n  images.extend([os.path.join('DatasetStore/Images/',breed,f) for f in image_files])\n  annotations.extend([os.path.join('DatasetStore/Annotation/',breed,f.replace(\".jpg\",\"\")) for f in image_files])\n\n\n\nfor idx, ann in enumerate(annotations):\n    annotations[idx] = ann.split(\"/\")[2] # add dog breed name\n\n# Prepare train test validate datasets\nXs = np.asarray(images)\nYs = np.asarray(annotations)\n\nprint('Xs shape',Xs.shape)\nprint(Xs[:5])\nprint('Ys shape',Ys.shape)\nprint(Ys[:5])\n\n\n\n# Split into train_validate + test data\ntrain_validate_x,test_x, train_validate_y, test_y = train_test_split(Xs,Ys,test_size=0.1)\nprint(\"train_validate_x shape:\",train_validate_x.shape)\nprint('train_validate_x[:5]:',train_validate_x[:5])\nprint(\"train_validate_y shape:\",train_validate_y.shape)\nprint('train_validate_y[:5]:',train_validate_y[:5])\nprint(\"test_x shape:\",test_x.shape)\nprint('test_x[:5]:',test_x[:5])\nprint(\"test_y shape:\",test_y.shape)\nprint('test_y[:5]:',test_y[:5])","metadata":{"id":"kJMowUie220k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f630fc7f-c488-468e-8f2f-3d47fe98d4e9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View a few train images\nfig = plt.figure(figsize=(15,10))\n\nfor idx in range(9):\n  sample_input = cv2.imread(train_validate_x[idx])\n  sample_input = cv2.cvtColor(sample_input, cv2.COLOR_BGR2RGB)\n  breed = train_validate_y[idx];\n  axs = fig.add_subplot(3,3,idx+1)\n  axs.set_title(breed)\n  plt.imshow(sample_input)\n  plt.axis('off')\nplt.show();","metadata":{"id":"P7B-bQxXpNGD","colab":{"base_uri":"https://localhost:8080/","height":829},"outputId":"bf96e6f0-6c7c-4500-f6d2-edfa36b6bf9f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Build Data Generator**","metadata":{"id":"N-YmrNyQtxFl"}},{"cell_type":"code","source":"validation_percent = 0.2\nimage_width = 128\nimage_height = 128\nnum_channels = 3\nnum_classes = len(breed_list);\n\nepochs = 50\ntrain_batch_size = 32\nvalidation_batch_size = 32\ntest_batch_size = 32\ntrain_shuffle_size = train_batch_size * 3\nvalidation_shuffle_size = validation_batch_size * 3\n\n# Split data into train / validation\ntrain_x, validate_x, train_y, validate_y = train_test_split(train_validate_x, train_validate_y, test_size=validation_percent)\n\n#  Converts to binary class matrix (One-hot-encoded)\ntrain_processed_y = np.asarray([label2index[label] for label in train_y])\nvalidate_processed_y = np.asarray([label2index[label] for label in validate_y])\ntest_processed_y = np.asarray([label2index[label] for label in test_y])\ntrain_processed_y = to_categorical(train_processed_y, num_classes=num_classes, dtype='float32')\nvalidate_processed_y = to_categorical(validate_processed_y, num_classes=num_classes, dtype='float32')\ntest_processed_y = to_categorical(test_processed_y, num_classes=num_classes, dtype='float32')\ntrain_data_count = train_x.shape[0]\n\n# Use int instead of np.int\nsteps_per_epoch = int(train_data_count / train_batch_size)\nvalidation_data_count = validate_x.shape[0]\n\n# Use int instead of np.int\nvalidation_steps = int(validation_data_count / validation_batch_size)\n\n# Prepare the data\ndef load_image(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=num_channels)\n    image = tf.image.resize(image,[image_height,image_width])\n    return image, label\n\n# Normalize pixels\ndef normalize(image, label):\n    image = image/255\n    return image, label\n\ndef build_data_generators(train_data_process_list=[load_image,normalize],validate_data_process_list=[load_image,normalize],test_data_process_list=[load_image,normalize]):\n     # Create TF Dataset\n    train_data = tf.data.Dataset.from_tensor_slices((train_x.tolist(), train_processed_y.tolist()))\n    validation_data = tf.data.Dataset.from_tensor_slices((validate_x.tolist(), validate_processed_y.tolist()))\n    test_data = tf.data.Dataset.from_tensor_slices((test_x.tolist(), test_processed_y.tolist()))\n\n    # Train data\n    # Shuffle\n    train_data = train_data.shuffle(train_data_count)\n    \n    # Apply all data processing logic\n    for process in train_data_process_list:\n        train_data = train_data.map(process, num_parallel_calls=AUTOTUNE)\n    train_data = train_data.repeat(epochs).batch(train_batch_size)\n\n    # Validation data\n    # Shuffle\n\n    validation_data = validation_data.shuffle(validation_data_count)\n\n    # Apply all data processing logic\n\n    for process in validate_data_process_list:\n        validation_data = validation_data.map(process, num_parallel_calls=AUTOTUNE)\n\n    validation_data = validation_data.repeat(epochs).batch(validation_batch_size)\n\n    # Test data\n    # Apply all data processing logic\n\n    for process in test_data_process_list:\n        test_data = test_data.map(process, num_parallel_calls=AUTOTUNE)\n    test_data = test_data.repeat(1).batch(test_batch_size)\n    return train_data, validation_data, test_data\n\ntrain_data, validation_data, test_data = build_data_generators()\nprint(\"train_data\",train_data)\nprint(\"validation_data\",validation_data)\nprint(\"test_data\",test_data)","metadata":{"id":"rgGE7baztwqj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7de66e4c-48e9-4af2-ec67-f174500a8896","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Utility Function**","metadata":{"id":"Z0CDan-5dhsC"}},{"cell_type":"code","source":"class JsonEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, decimal.Decimal):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return super(JsonEncoder, self).default(obj)\n\ndef get_model_metrics():\n    with open(\"./SavedModels/model_metrics.json\") as json_file:\n        model_metrics = json.load(json_file)\n    return model_metrics\n\ndef save_model_metrics(model_name=\"model_1\",metrics={}):\n    if os.path.exists(\"./SavedModels/model_metrics.json\"):\n        with open(\"./SavedModels/model_metrics.json\") as json_file:\n            model_metrics = json.load(json_file)\n    else:\n        model_metrics = {}\n    model_metrics[model_name] = metrics\n\n    # Save the json\n    with open(\"./SavedModels/model_metrics.json\", 'w') as json_file:\n        json_file.write(json.dumps(model_metrics, cls=JsonEncoder))\n\ndef save_model(path=\"./SavedModels\",model_name=\"model01\"):\n    filename = \"./SavedModels/\"\n    os.makedirs(os.path.dirname(filename), exist_ok=True)\n    \n    # Save the enitire model (structure + weights)\n    model.save(os.path.join(path,model_name+\".hdf5\"))\n\n    # Save only the weights\n    model.save_weights(os.path.join(path,model_name+\".h5\"))\n\n    # Save the structure only\n    model_json = model.to_json()\n    with open(os.path.join(path,model_name+\".json\"), \"w\") as json_file:\n        json_file.write(model_json)\n\ndef get_model_size(path=\"./SavedModels\",model_name=\"model01\"):\n    model_size = os.stat(os.path.join(path,model_name+\".hdf5\")).st_size\n    return model_size\n\ndef evaluate_save_model(model,training_results,test_data,execution_time, learning_rate, batch_size, epochs, optimizer,momentum = None, save=True):\n    # Get the model train history\n    model_train_history = training_results.history\n\n    # Get the number of epochs the training was run for\n    num_epochs = len(model_train_history[\"loss\"])\n\n\n\n    # Plot training results\n    fig = plt.figure(figsize=(15,5))\n    axs = fig.add_subplot(1,2,1)\n    axs.set_title('Loss')\n\n    # Plot all metrics\n    for metric in [\"loss\",\"val_loss\"]:\n        axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n    axs.legend()\n    axs = fig.add_subplot(1,2,2)\n    axs.set_title('Accuracy')\n\n    # Plot all metrics\n    for metric in [\"accuracy\",\"val_accuracy\"]:\n        axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n    axs.legend()\n    plt.show()\n\n    # Evaluate on test data\n    evaluation_results = model.evaluate(test_data)\n    print('Evaluation results: [loss, accuracy]', evaluation_results)\n\n    if save:\n        # Save model\n        save_model(model_name=model.name)\n        model_size = get_model_size(model_name=model.name)\n\n        # Save model history\n        with open(os.path.join(\"./SavedModels\",model.name+\"_train_history.json\"), \"w\") as json_file:\n            json_file.write(json.dumps(model_train_history,cls=JsonEncoder))\n\n        trainable_parameters = model.count_params()\n\n        # Save model metrics\n        metrics ={\n            \"trainable_parameters\":trainable_parameters,\n            \"execution_time\":execution_time,\n            \"loss\":evaluation_results[0],\n            \"accuracy\":evaluation_results[1],\n            \"model_size\":model_size,\n            \"learning_rate\":learning_rate,\n            \"batch_size\":batch_size,\n            'momentum': momentum,\n            \"epochs\":epochs,\n            \"optimizer\":type(optimizer).__name__\n        }\n\n        save_model_metrics(model_name=model.name,metrics=metrics)","metadata":{"id":"105hSkZIdkDY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **VGG16**\n\nUse VGG16 as the base and fine tune the last conv2d block for our problem","metadata":{"id":"BI3it2zzw9TQ"}},{"cell_type":"markdown","source":"### Build model","metadata":{"id":"uuScag4O1KkB"}},{"cell_type":"code","source":"# vgg16 with fine tuning the last conv2d base\nvgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(image_height,image_width,3))\n\ndef view_layers(model):\n    layers = model.layers\n    layers_list = []\n\n    for idx, layer in enumerate(layers):\n        layers_list.append({\n            'layer': type(layer).__name__,\n            'trainable':layer.trainable\n        })\n\n    df = pd.DataFrame(layers_list)\n    return df\n\nlayers_df = view_layers(vgg16)\nprint(layers_df[10:])","metadata":{"id":"LEOx-udiw_2D","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1ea1854-6296-4496-c361-a18f9692919b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training params","metadata":{"id":"L8cu91Gm1S25"}},{"cell_type":"code","source":"############################\n# Training Params\n############################\nlearning_rate = 0.001\nbatch_size = 32\nepochs = 50\n############################\n# Set all layers as trainable false execpt last conv block\nfor layer in vgg16.layers[:-4]:\n    layer.trainable = False\n\n# Input\nmodel_input = vgg16.layers[0].input\n\n# Final pool layer\nhidden = vgg16.layers[-1]\nprint(\"Pool Layer\",hidden)\n\n# Flatten\nhidden = layers.Flatten()(hidden.output)\n\n#  Hidden Layer, Classification Block\nhidden = layers.Dense(units=1024, activation='relu')(hidden)\nhidden = layers.Dense(units=1024, activation='relu')(hidden)\n\n\n# Output Layer\noutput = layers.Dense(units=num_classes, activation='softmax')(hidden)\n\n\n# Build model\nmodel = Model(model_input, output, name='VGG16')\n\n# Optimizer\noptimizer = optimizers.SGD(lr=learning_rate)\n\n\n# Loss\nloss = losses.categorical_crossentropy\n\n# Compile\nmodel.compile(loss=loss,\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n\n\n#print(model.summary())\nlayers_df = view_layers(model)\nprint(layers_df.head(25))","metadata":{"id":"_BDBVaX8xmS4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad28229a-fbf5-4e03-ef76-962debda8c8c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train model","metadata":{"id":"J6LNZStN2ABx"}},{"cell_type":"code","source":"# Train model\n# Early Stopping\n\nearlystopping = EarlyStopping(monitor='val_accuracy', patience=10);\n\n# Model Checkpoint\ncheckpoint_filepath = './Checkpoints/checkpoint_VGG16'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    verbose=1,\n    mode='max',\n    save_best_only=True)\n\nstart_time = time.time()\ntraining_results = model.fit(\n        train_data,\n        validation_data=validation_data,\n        callbacks=[earlystopping,model_checkpoint_callback],\n        epochs=epochs,\n        verbose=1,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps)\n\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)\n","metadata":{"id":"dWmr46Ar1ItL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a56d7940-1333-420e-9f87-47344ce8cae6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate and Save","metadata":{"id":"dOjxxq3X2GTK"}},{"cell_type":"code","source":"# Evaluate and Save model\nevaluate_save_model(model,training_results,test_data,execution_time, learning_rate, batch_size, epochs, optimizer)","metadata":{"id":"3lH3aELM2Irh","colab":{"base_uri":"https://localhost:8080/","height":370},"outputId":"ee37c4b4-f3be-477e-89d4-248c7ba08071","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nimport tensorflow as tf\n\n# Download the model repository\nrepo_path = snapshot_download(\"zeku74/ResNet50V2_Dog_Breed_Classifier\")\n\n# Load the TensorFlow model\nmodel = tf.keras.models.load_model(repo_path)\n\n# Check the model summary\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom huggingface_hub import snapshot_download\nimport numpy as np\n\n# Download the model from Hugging Face Hub\nrepo_path = snapshot_download(\"zeku74/ResNet50V2_Dog_Breed_Classifier\")\n\n# Load the TensorFlow model\nmodel = tf.keras.models.load_model(repo_path)\n\n# Check the model summary\nmodel.summary()\n\n# Data augmentation functions\ndef adjust_brightness(image, label):\n    return tf.image.adjust_brightness(image, 0.01), label\n\ndef adjust_contrast(image, label):\n    return tf.image.adjust_contrast(image, 1.2), label\n\ndef rotate_image(image, label):\n    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n    return image, label\n\ndef random_zoom(image, label):\n    scales = list(np.arange(0.8, 1.0, 0.1))  # Zoom scales\n    scale = tf.random.shuffle(scales)[0]\n    new_size = tf.cast(tf.shape(image)[:2] * scale, tf.int32)\n    image = tf.image.resize_with_crop_or_pad(image, new_size[0], new_size[1])\n    return tf.image.resize(image, [224, 224]), label\n\n# Preprocessing and augmentation combined with model prediction\ndef augment_with_model(image, label):\n    # Resize image to 224x224 for ResNet50V2 input\n    image = tf.image.resize(image, [224, 224])\n    \n    # Normalize the image (you might need the exact normalization applied during training)\n    image = tf.keras.applications.resnet_v2.preprocess_input(image)\n\n    # Add batch dimension to image (required for model input)\n    image = tf.expand_dims(image, axis=0)\n\n    # Make predictions with the model\n    predictions = model(image)  # Get predictions (probabilities or logits)\n    \n    # Post-process predictions if needed (e.g., apply a softmax or argmax)\n    predicted_class = tf.argmax(predictions, axis=-1)  # Get the predicted class (if classification)\n    \n    # Returning the image (augmented) and label as output, can also return the predicted class if needed\n    return image[0], label  # Image (augmented) and original label\n\n# Data processing and augmentation pipeline\ndata_process_list = [adjust_brightness, adjust_contrast, rotate_image, random_zoom, augment_with_model]\n\n# Placeholder function to simulate data generator construction\ndef build_data_generators(train_data_process_list):\n    # For demonstration, returning placeholders for train, validation, and test data\n    train_data = \"train_data_placeholder\"\n    validation_data = \"validation_data_placeholder\"\n    test_data = \"test_data_placeholder\"\n    return train_data, validation_data, test_data\n\n# Build data generators for train, validation, and test\ntrain_data, validation_data, test_data = build_data_generators(train_data_process_list=data_process_list)\n\nprint(\"train_data\", train_data)\nprint(\"validation_data\", validation_data)\nprint(\"test_data\", test_data)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ResNet50V2 with Adam optimizer**","metadata":{"id":"NHaGRXGN_OQ1"}},{"cell_type":"code","source":"resnet50_v2 = ResNet50V2(\ninclude_top=False,\ninput_shape=(128, 128, 3)\n)","metadata":{"id":"SR4grSMd_iGx","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"bffff915-157b-46b5-c00f-51ae63a197a8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Build model","metadata":{"id":"bv2zIFKjgejo"}},{"cell_type":"code","source":"# Build model for Resnet\ndef build_resnet_model(model_name = 'ResNet50V2',print_summary=True):\n  # Set all layers as hidden\n  for layer in resnet50_v2.layers:\n      layer.trainable = False\n\n  # Input\n  model_input = resnet50_v2.layers[0].input\n\n  # Extract final pool layer\n  hidden = resnet50_v2.layers[-1]\n    \n  # Flatten\n  hidden = layers.Flatten()(hidden.output)\n\n  # Output Layer\n  output = layers.Dense(units=120, activation='softmax')(hidden)\n\n  # Create model\n  model = Model(model_input, output, name=model_name)\n\n  # Print the model architecture\n  if print_summary:\n    print(model.summary())\n\n  return model","metadata":{"id":"7e1x6jqzCoeW","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training params","metadata":{"id":"ZVvmAnnKDGK5"}},{"cell_type":"code","source":"############################\n# Training Params\n############################\nbatch_size = 32\nepochs = 50\n############################\n# Early Stopping\nearlystopping = EarlyStopping(monitor='val_accuracy', patience=10);\n\n# Model Checkpoint\ncheckpoint_filepath = './Checkpoints/checkpoint_ResNet50V2'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    verbose=1,\n    model_input='max',\n    save_best_only=True)\n\n# Build the model\nmodel = build_resnet_model()\n\n# Optimier\noptimizer = optimizers.Adam()\n\n# Loss\nloss = losses.categorical_crossentropy\n\n# Compile\nmodel.compile(loss=loss,\n                  optimizer=optimizer,\n                  metrics=['accuracy'])","metadata":{"id":"UzWnl6LQDFQc","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"66d3cd6e-e0f9-45ab-e794-2d9896c8b41c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train model","metadata":{"id":"xA3vyMD4Hk95"}},{"cell_type":"code","source":"# Train model\nstart_time = time.time()\ntraining_results = model.fit(\n        train_data,\n        validation_data=validation_data,\n        epochs=epochs,\n        callbacks=[earlystopping,model_checkpoint_callback],\n        verbose=1,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps)\n\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)","metadata":{"id":"4Db91Tv1Hm5P","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2c35a0c7-9957-42c3-abd5-ff6084e77f04","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate and Save","metadata":{"id":"HYx2M_5hXc6I"}},{"cell_type":"code","source":"# Evaluate and Save model\nlearning_rate = 0.001;\nevaluate_save_model(model,training_results,test_data,execution_time, learning_rate, batch_size, epochs, optimizer)","metadata":{"id":"_wVYbxkrXe4X","colab":{"base_uri":"https://localhost:8080/","height":370},"outputId":"d1ada99e-fbd6-47da-f706-132792724ab8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Add data augmentation to ResNet50V2","metadata":{"id":"eVHCEUayfMxI"}},{"cell_type":"code","source":"# Create data augmentation processors\n# https://www.tensorflow.org/api_docs/python/tf/image/adjust_brightness\ndef adjust_brightness(image, label):\n    return tf.image.adjust_brightness(image, 0.01), label\n\n# https://www.tensorflow.org/api_docs/python/tf/image/adjust_contrast\ndef adjust_contrast(image, label):\n    return tf.image.adjust_contrast(image, 1.2), label\n    \ndef rotate_image(image, label):\n    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n    return image, label\n\ndef random_zoom(image, label):\n    scales = list(np.arange(0.8, 1.0, 0.1))  # Zoom scales\n    scale = tf.random.shuffle(scales)[0]\n    new_size = tf.cast(tf.shape(image)[:2] * scale, tf.int32)\n    image = tf.image.resize_with_crop_or_pad(image, new_size[0], new_size[1])\n    return tf.image.resize(image, [224, 224]), label\n\n\n# Apply data processing + data augmentation steps\ndata_process_list=[load_image, normalize, adjust_brightness, adjust_contrast]\n\n# Build data generators for train, validate, test\ntrain_data, validation_data, test_data = build_data_generators(train_data_process_list=data_process_list)\nprint(\"train_data\",train_data)\nprint(\"validation_data\",validation_data)\nprint(\"test_data\",test_data)","metadata":{"id":"xc6bfPpNfSpy","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"bc953638-6959-4d2c-c89a-7b9057982ca2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Build model","metadata":{"id":"CJNcgYyIghp-"}},{"cell_type":"code","source":"############################\n# Training Params\n############################\nbatch_size = 32\nepochs = 50\n############################\n# Early Stopping\nearlystopping = EarlyStopping(monitor='val_accuracy', patience=10);\n\n# Model Checkpoint\ncheckpoint_filepath = './Checkpoints/checkpoint_ResNet50V2DataAug'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    verbose=1,\n    mode='max',\n    save_best_only=True)\n\n# Build the model\nmodel = build_resnet_model(model_name='ResNet50V2_DataAug')\n\n# Loads the weights\ncheckpoint_path = './Checkpoints/checkpoint_ResNet50V2'\nmodel.load_weights(checkpoint_path)\n\n# Optimier\noptimizer = optimizers.Adam()\n\n# Loss\nloss = losses.categorical_crossentropy\n\n# Compile\nmodel.compile(loss=loss,\n                  optimizer=optimizer,\n                  metrics=['accuracy'])","metadata":{"id":"1rCmZAQCg3oI","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f70e7ab9-f065-4408-e613-b972fc64bcd6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train model","metadata":{"id":"ZhWYtHsdvUVP"}},{"cell_type":"code","source":"# Train model\nstart_time = time.time()\ntraining_results = model.fit(\n        train_data,\n        validation_data=validation_data,\n        epochs=epochs,\n        callbacks=[earlystopping,model_checkpoint_callback],\n        verbose=1,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps)\n\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)","metadata":{"id":"rFr6PEMrvXVg","colab":{"base_uri":"https://localhost:8080/","height":870},"outputId":"e1787429-4975-4215-d57b-4556c0a44a28","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate and Save","metadata":{"id":"gCSqRvSczJYQ"}},{"cell_type":"code","source":"# Evaluate and Save model\nevaluate_save_model(model,training_results,test_data,execution_time, learning_rate, batch_size, epochs, optimizer)","metadata":{"id":"L3EhTaPNzOF0","colab":{"base_uri":"https://localhost:8080/","height":370},"outputId":"c736c8b8-9109-46b4-d40e-b8a41fae20a9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Display predictions","metadata":{"id":"-o3jfbAnTsLF"}},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the pre-trained model and its weights\nprediction_model = tf.keras.models.load_model('./SavedModels/ResNet50V2_DataAug.hdf5')\ncheckpoint_path = './Checkpoints/checkpoint_ResNet50V2DataAug'\nprediction_model.load_weights(checkpoint_path)\n\n# Define the target size for the images\ntarget_size = (224, 224)  # Adjust based on your model's input requirements\n\n# Load Test images\ntest_x_display = []\nfor path in test_x:\n    # Read image\n    image = cv2.imread(path)\n    # Convert to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # Resize image to target size\n    image = cv2.resize(image, target_size)\n    # Append to display list\n    test_x_display.append(image)\n\n# Convert to NumPy array\ntest_x_display = np.asarray(test_x_display)\n\n# Make predictions\ntest_predictions = prediction_model.predict(test_data)\n\n# Add true and predicted breed for each dog image\n# Mark it green if prediction is true, otherwise red\n# Count the total number of true predictions for the first 50 images\ntrue_predict = 0\nfalse_predict = 0\nfig = plt.figure(figsize=(20, 16))\n\nfor i, file in enumerate(test_x_display[:50]):\n    axs = fig.add_subplot(10, 5, i + 1)\n    axs.set_aspect('equal')\n    predicted_breed = index2label[test_predictions.argmax(axis=1)[i]][10:]  # Truncate leading unnecessary letters\n    true_breed = test_y[i][10:]\n\n    # Color code true/false predictions\n    if true_breed == predicted_breed:\n        axs.set_title('Prediction: ' + predicted_breed + '\\n' + 'Truth: ' + true_breed, color='green')\n        true_predict += 1\n    else:\n        axs.set_title('Prediction: ' + predicted_breed + '\\n' + 'Truth: ' + true_breed, color='red')\n        false_predict += 1\n\n    plt.imshow(test_x_display[i])\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Print the count of true and false predictions\nprint('# of true predictions: ', true_predict)\nprint('# of false predictions: ', false_predict)\n","metadata":{"id":"ubqo8bPOSbhM","colab":{"base_uri":"https://localhost:8080/","height":901},"outputId":"43b37e07-4d7d-4bd2-cd7b-8346b406cb41","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Compare all models**","metadata":{"id":"lajkNewEC27n"}},{"cell_type":"code","source":"# Compare model metrics\n# Check if the file exists before attempting to read it.\nif os.path.exists(\"./SavedModels/model_metrics.json\"):\n    view_metrics = pd.read_json(\"./SavedModels/model_metrics.json\")\n    view_metrics = view_metrics.T\n    # Format columns\n    view_metrics['accuracy'] = view_metrics['accuracy']*100\n    view_metrics['accuracy'] = view_metrics['accuracy'].map('{:,.2f}%'.format)\n    view_metrics['trainable_parameters'] = view_metrics['trainable_parameters'].map('{:,.0f}'.format)\n    view_metrics['execution_time'] = view_metrics['execution_time'].map('{:,.2f} mins'.format)\n    #view_metrics['loss'] = view_metrics['loss'].map('{:,.2f}'.format)\n    view_metrics['model_size'] = view_metrics['model_size']/1000000\n    view_metrics['model_size'] = view_metrics['model_size'].map('{:,.0f} MB'.format)\n    print('Number of models:',view_metrics.shape[0])\nelse:\n    print(\"Error: The file './SavedModels/model_metrics.json' does not exist. \"\n          \"Please ensure that you have saved model metrics before attempting to read them.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"view_metrics.sort_values(by=['accuracy'],ascending=False).head(10)","metadata":{"id":"00NY39m1C5pe","colab":{"base_uri":"https://localhost:8080/","height":162},"outputId":"021a1348-9ff3-465d-b139-ab70f2c8b6e8","trusted":true},"outputs":[],"execution_count":null}]}