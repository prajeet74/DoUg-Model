{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":791828,"sourceType":"datasetVersion","datasetId":119698}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, optimizers\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom huggingface_hub import push_to_hub_keras\nimport json\nimport shutil\nfrom pathlib import Path\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:17:33.137158Z","iopub.execute_input":"2025-02-21T13:17:33.137431Z","iopub.status.idle":"2025-02-21T13:17:33.143106Z","shell.execute_reply.started":"2025-02-21T13:17:33.137410Z","shell.execute_reply":"2025-02-21T13:17:33.142041Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Configuration\nIMG_SIZE = 299  # Xception's default input size\nBATCH_SIZE = 32\nEPOCHS = 50\nDATASET_PATH = \"/kaggle/input/stanford-dogs-dataset\"\nIMAGES_PATH = os.path.join(DATASET_PATH, \"images\", \"Images\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:17:33.144410Z","iopub.execute_input":"2025-02-21T13:17:33.144743Z","iopub.status.idle":"2025-02-21T13:17:33.155182Z","shell.execute_reply.started":"2025-02-21T13:17:33.144712Z","shell.execute_reply":"2025-02-21T13:17:33.154553Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\ndef parse_breed_name(folder_name):\n    \"\"\"Extract breed name from folder name (e.g., 'n02085620-Chihuahua' -> 'Chihuahua')\"\"\"\n    return folder_name.split('-')[1]\n\ndef prepare_data():\n    \"\"\"Prepare train/validation splits while maintaining folder structure\"\"\"\n    # Get all breed folders\n    breed_folders = [f for f in os.listdir(IMAGES_PATH) if os.path.isdir(os.path.join(IMAGES_PATH, f))]\n    \n    # Create train and validation directories\n    train_dir = Path('processed_dataset/train')\n    valid_dir = Path('processed_dataset/valid')\n    train_dir.mkdir(parents=True, exist_ok=True)\n    valid_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Dictionary to store class mapping\n    class_mapping = {}\n    \n    for i, breed_folder in enumerate(sorted(breed_folders)):\n        breed_path = os.path.join(IMAGES_PATH, breed_folder)\n        breed_name = parse_breed_name(breed_folder)\n        class_mapping[breed_folder] = {'name': breed_name, 'index': i}\n        \n        # Get all images for this breed\n        images = [f for f in os.listdir(breed_path) if f.endswith('.jpg')]\n        \n        # Split into train/validation\n        train_images, valid_images = train_test_split(\n            images, test_size=0.2, random_state=42\n        )\n        \n        # Create breed directories in train and validation\n        (train_dir / breed_folder).mkdir(exist_ok=True)\n        (valid_dir / breed_folder).mkdir(exist_ok=True)\n        \n        # Copy images to respective directories\n        for img in train_images:\n            shutil.copy2(\n                os.path.join(breed_path, img),\n                str(train_dir / breed_folder / img)\n            )\n        for img in valid_images:\n            shutil.copy2(\n                os.path.join(breed_path, img),\n                str(valid_dir / breed_folder / img)\n            )\n    \n    return class_mapping, str(train_dir), str(valid_dir)\n\ndef create_model(num_classes):\n    base_model = Xception(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    \n    base_model.trainable = False\n    \n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.5),\n        layers.Dense(1024, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:17:33.156621Z","iopub.execute_input":"2025-02-21T13:17:33.156875Z","iopub.status.idle":"2025-02-21T13:17:33.170028Z","shell.execute_reply.started":"2025-02-21T13:17:33.156856Z","shell.execute_reply":"2025-02-21T13:17:33.169249Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\ndef setup_data_augmentation():\n    train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n    \n    valid_datagen = ImageDataGenerator(\n        rescale=1./255\n    )\n    \n    return train_datagen, valid_datagen\n\ndef prepare_data_generators(train_datagen, valid_datagen, train_dir, valid_dir):\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical'\n    )\n    \n    validation_generator = valid_datagen.flow_from_directory(\n        valid_dir,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical'\n    )\n    \n    return train_generator, validation_generator\n\ndef train_model(model, train_generator, validation_generator):\n    callbacks = [\n        ModelCheckpoint(\n            'best_model.keras',\n            monitor='val_accuracy',\n            mode='max',\n            save_best_only=True,\n            verbose=1\n        ),\n        EarlyStopping(\n            monitor='val_loss',\n            mode='min',\n            patience=5,\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.1,\n            patience=3,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]\n    \n    model.compile(\n        optimizer=optimizers.Adam(learning_rate=1e-4),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    history = model.fit(\n        train_generator,\n        epochs=EPOCHS,\n        validation_data=validation_generator,\n        callbacks=callbacks\n    )\n    \n    return model, history\n\ndef fine_tune_model(model, train_generator, validation_generator):\n    # Unfreeze the last few layers\n    base_model = model.layers[0]\n    base_model.trainable = True\n    \n    for layer in base_model.layers[:-30]:\n        layer.trainable = False\n    \n    model.compile(\n        optimizer=optimizers.Adam(learning_rate=1e-5),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    callbacks = [\n        ModelCheckpoint(\n            'best_finetuned_model.keras',\n            monitor='val_accuracy',\n            mode='max',\n            save_best_only=True,\n            verbose=1\n        ),\n        EarlyStopping(\n            monitor='val_loss',\n            mode='min',\n            patience=5,\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.1,\n            patience=3,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]\n    \n    history = model.fit(\n        train_generator,\n        epochs=20,\n        validation_data=validation_generator,\n        callbacks=callbacks\n    )\n    \n    return model, history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:17:33.170813Z","iopub.execute_input":"2025-02-21T13:17:33.171006Z","iopub.status.idle":"2025-02-21T13:17:33.180791Z","shell.execute_reply.started":"2025-02-21T13:17:33.170989Z","shell.execute_reply":"2025-02-21T13:17:33.180048Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# def save_to_huggingface(model, class_mapping):\n#     # Save model configuration\n#     config = {\n#         \"img_size\": IMG_SIZE,\n#         \"num_classes\": len(class_mapping),\n#         \"class_mapping\": class_mapping,\n#         \"preprocessing\": \"normalize_between_0_and_1\"\n#     }\n    \n#     with open(\"config.json\", \"w\") as f:\n#         json.dump(config, f)\n\n#     # Save to Hugging Face\n#     push_to_hub_keras(\n#         model=model,\n#         repo_id=HF_REPO_ID,\n#         token=HF_TOKEN,\n#         config=config,\n#         commit_message=\"Add Stanford Dogs Xception model\"\n#     )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:17:33.181478Z","iopub.execute_input":"2025-02-21T13:17:33.181777Z","iopub.status.idle":"2025-02-21T13:17:33.194928Z","shell.execute_reply.started":"2025-02-21T13:17:33.181749Z","shell.execute_reply":"2025-02-21T13:17:33.194220Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\ndef main():\n    print(\"Preparing dataset...\")\n    class_mapping, train_dir, valid_dir = prepare_data()\n    num_classes = len(class_mapping)\n    \n    print(\"Creating model...\")\n    model = create_model(num_classes)\n    \n    print(\"Setting up data generators...\")\n    train_datagen, valid_datagen = setup_data_augmentation()\n    train_generator, validation_generator = prepare_data_generators(\n        train_datagen, valid_datagen, train_dir, valid_dir\n    )\n    \n    print(\"Starting initial training...\")\n    model, history = train_model(model, train_generator, validation_generator)\n    \n    print(\"Starting fine-tuning...\")\n    model, ft_history = fine_tune_model(\n        model, train_generator, validation_generator\n    )\n    \n    # print(\"Saving model to Hugging Face...\")\n    # save_to_huggingface(model, class_mapping)\n    # print(f\"Model saved to HuggingFace: {HF_REPO_ID}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T13:17:33.308530Z","iopub.execute_input":"2025-02-21T13:17:33.308863Z","iopub.status.idle":"2025-02-21T16:22:08.959385Z","shell.execute_reply.started":"2025-02-21T13:17:33.308836Z","shell.execute_reply":"2025-02-21T16:22:08.958640Z"}},"outputs":[{"name":"stdout","text":"Preparing dataset...\nCreating model...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nSetting up data generators...\nFound 16418 images belonging to 120 classes.\nFound 4162 images belonging to 120 classes.\nStarting initial training...\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.3423 - loss: 3.6338\nEpoch 1: val_accuracy improved from -inf to 0.87650, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 696ms/step - accuracy: 0.3427 - loss: 3.6315 - val_accuracy: 0.8765 - val_loss: 0.6016 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.8074 - loss: 0.8151\nEpoch 2: val_accuracy improved from 0.87650 to 0.89476, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 679ms/step - accuracy: 0.8074 - loss: 0.8149 - val_accuracy: 0.8948 - val_loss: 0.3907 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.8358 - loss: 0.5926\nEpoch 3: val_accuracy did not improve from 0.89476\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 676ms/step - accuracy: 0.8358 - loss: 0.5926 - val_accuracy: 0.8945 - val_loss: 0.3493 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step - accuracy: 0.8422 - loss: 0.5319\nEpoch 4: val_accuracy improved from 0.89476 to 0.89596, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 671ms/step - accuracy: 0.8422 - loss: 0.5320 - val_accuracy: 0.8960 - val_loss: 0.3316 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.8487 - loss: 0.5048\nEpoch 5: val_accuracy improved from 0.89596 to 0.89885, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 672ms/step - accuracy: 0.8487 - loss: 0.5048 - val_accuracy: 0.8988 - val_loss: 0.3245 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.8481 - loss: 0.4913\nEpoch 6: val_accuracy improved from 0.89885 to 0.90221, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 677ms/step - accuracy: 0.8481 - loss: 0.4913 - val_accuracy: 0.9022 - val_loss: 0.3156 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - accuracy: 0.8597 - loss: 0.4545\nEpoch 7: val_accuracy did not improve from 0.90221\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 680ms/step - accuracy: 0.8597 - loss: 0.4545 - val_accuracy: 0.8991 - val_loss: 0.3157 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.8574 - loss: 0.4415\nEpoch 8: val_accuracy did not improve from 0.90221\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 673ms/step - accuracy: 0.8574 - loss: 0.4416 - val_accuracy: 0.8976 - val_loss: 0.3138 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step - accuracy: 0.8625 - loss: 0.4331\nEpoch 9: val_accuracy did not improve from 0.90221\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 670ms/step - accuracy: 0.8625 - loss: 0.4331 - val_accuracy: 0.9005 - val_loss: 0.3082 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.8687 - loss: 0.4210\nEpoch 10: val_accuracy did not improve from 0.90221\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 671ms/step - accuracy: 0.8687 - loss: 0.4210 - val_accuracy: 0.9010 - val_loss: 0.3144 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611ms/step - accuracy: 0.8657 - loss: 0.4148\nEpoch 11: val_accuracy did not improve from 0.90221\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 669ms/step - accuracy: 0.8657 - loss: 0.4148 - val_accuracy: 0.8996 - val_loss: 0.3117 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - accuracy: 0.8743 - loss: 0.3963\nEpoch 12: val_accuracy did not improve from 0.90221\n\nEpoch 12: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 669ms/step - accuracy: 0.8743 - loss: 0.3963 - val_accuracy: 0.8981 - val_loss: 0.3089 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611ms/step - accuracy: 0.8744 - loss: 0.3803\nEpoch 13: val_accuracy did not improve from 0.90221\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 668ms/step - accuracy: 0.8744 - loss: 0.3803 - val_accuracy: 0.9000 - val_loss: 0.2996 - learning_rate: 1.0000e-05\nEpoch 14/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.8820 - loss: 0.3747\nEpoch 14: val_accuracy improved from 0.90221 to 0.90293, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 668ms/step - accuracy: 0.8820 - loss: 0.3747 - val_accuracy: 0.9029 - val_loss: 0.2987 - learning_rate: 1.0000e-05\nEpoch 15/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - accuracy: 0.8810 - loss: 0.3744\nEpoch 15: val_accuracy did not improve from 0.90293\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 668ms/step - accuracy: 0.8810 - loss: 0.3744 - val_accuracy: 0.9017 - val_loss: 0.2984 - learning_rate: 1.0000e-05\nEpoch 16/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.8802 - loss: 0.3756\nEpoch 16: val_accuracy did not improve from 0.90293\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 667ms/step - accuracy: 0.8802 - loss: 0.3756 - val_accuracy: 0.9025 - val_loss: 0.2979 - learning_rate: 1.0000e-05\nEpoch 17/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.8792 - loss: 0.3764\nEpoch 17: val_accuracy improved from 0.90293 to 0.90413, saving model to best_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 668ms/step - accuracy: 0.8792 - loss: 0.3764 - val_accuracy: 0.9041 - val_loss: 0.2980 - learning_rate: 1.0000e-05\nEpoch 18/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.8759 - loss: 0.3757\nEpoch 18: val_accuracy did not improve from 0.90413\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 667ms/step - accuracy: 0.8759 - loss: 0.3757 - val_accuracy: 0.9034 - val_loss: 0.2983 - learning_rate: 1.0000e-05\nEpoch 19/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - accuracy: 0.8847 - loss: 0.3620\nEpoch 19: val_accuracy did not improve from 0.90413\n\nEpoch 19: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 668ms/step - accuracy: 0.8847 - loss: 0.3620 - val_accuracy: 0.9017 - val_loss: 0.2983 - learning_rate: 1.0000e-05\nEpoch 20/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.8831 - loss: 0.3782\nEpoch 20: val_accuracy did not improve from 0.90413\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 664ms/step - accuracy: 0.8831 - loss: 0.3782 - val_accuracy: 0.9020 - val_loss: 0.2982 - learning_rate: 1.0000e-06\nEpoch 21/50\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.8861 - loss: 0.3688\nEpoch 21: val_accuracy did not improve from 0.90413\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 667ms/step - accuracy: 0.8861 - loss: 0.3688 - val_accuracy: 0.9020 - val_loss: 0.2980 - learning_rate: 1.0000e-06\nEpoch 21: early stopping\nStarting fine-tuning...\nEpoch 1/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - accuracy: 0.8554 - loss: 0.4505\nEpoch 1: val_accuracy improved from -inf to 0.90125, saving model to best_finetuned_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 700ms/step - accuracy: 0.8554 - loss: 0.4505 - val_accuracy: 0.9012 - val_loss: 0.3128 - learning_rate: 1.0000e-05\nEpoch 2/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.8720 - loss: 0.3981\nEpoch 2: val_accuracy improved from 0.90125 to 0.90269, saving model to best_finetuned_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 679ms/step - accuracy: 0.8720 - loss: 0.3981 - val_accuracy: 0.9027 - val_loss: 0.3086 - learning_rate: 1.0000e-05\nEpoch 3/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.8805 - loss: 0.3854\nEpoch 3: val_accuracy did not improve from 0.90269\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 674ms/step - accuracy: 0.8805 - loss: 0.3854 - val_accuracy: 0.9012 - val_loss: 0.3068 - learning_rate: 1.0000e-05\nEpoch 4/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - accuracy: 0.8798 - loss: 0.3625\nEpoch 4: val_accuracy improved from 0.90269 to 0.90317, saving model to best_finetuned_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 681ms/step - accuracy: 0.8798 - loss: 0.3625 - val_accuracy: 0.9032 - val_loss: 0.3036 - learning_rate: 1.0000e-05\nEpoch 5/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.8858 - loss: 0.3482\nEpoch 5: val_accuracy improved from 0.90317 to 0.90533, saving model to best_finetuned_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 673ms/step - accuracy: 0.8858 - loss: 0.3482 - val_accuracy: 0.9053 - val_loss: 0.3028 - learning_rate: 1.0000e-05\nEpoch 6/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.8940 - loss: 0.3295\nEpoch 6: val_accuracy improved from 0.90533 to 0.90774, saving model to best_finetuned_model.keras\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 677ms/step - accuracy: 0.8940 - loss: 0.3295 - val_accuracy: 0.9077 - val_loss: 0.3046 - learning_rate: 1.0000e-05\nEpoch 7/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.8988 - loss: 0.3192\nEpoch 7: val_accuracy did not improve from 0.90774\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 675ms/step - accuracy: 0.8988 - loss: 0.3192 - val_accuracy: 0.9075 - val_loss: 0.3037 - learning_rate: 1.0000e-05\nEpoch 8/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.8972 - loss: 0.3243\nEpoch 8: val_accuracy did not improve from 0.90774\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 678ms/step - accuracy: 0.8972 - loss: 0.3243 - val_accuracy: 0.9032 - val_loss: 0.3055 - learning_rate: 1.0000e-05\nEpoch 9/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.9063 - loss: 0.2933\nEpoch 9: val_accuracy did not improve from 0.90774\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 680ms/step - accuracy: 0.9063 - loss: 0.2933 - val_accuracy: 0.9041 - val_loss: 0.3063 - learning_rate: 1.0000e-06\nEpoch 10/20\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.9039 - loss: 0.3017\nEpoch 10: val_accuracy did not improve from 0.90774\n\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 678ms/step - accuracy: 0.9039 - loss: 0.3017 - val_accuracy: 0.9049 - val_loss: 0.3057 - learning_rate: 1.0000e-06\nEpoch 10: early stopping\n","output_type":"stream"}],"execution_count":7}]}